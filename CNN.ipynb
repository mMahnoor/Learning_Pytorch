{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c33309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a32de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the tranform class for converting mnist image files\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8480fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data', train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d90909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e00b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1694c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb82bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92ed6a4",
   "metadata": {},
   "source": [
    "### Builing a model for convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923cd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Class\n",
    "\n",
    "class ConvolutionalNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)  # input, output, filter, stride\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        \n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        #second pass\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        \n",
    "        # Flattening\n",
    "        X = X.view(-1, 16*5*5)  # -1 is for varying batch size\n",
    "        \n",
    "        #Fully connected layers\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fbb431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ConvolutionalNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvolutionalNN().parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22a53b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "\n",
    "torch.manual_seed(41)\n",
    "\n",
    "cnn_model = ConvolutionalNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36c11475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74d8747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Optimization\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c6c234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Batch: 600  Loss: 0.12228913605213165\n",
      "Epoch: 0  Batch: 1200  Loss: 0.003188498318195343\n",
      "Epoch: 0  Batch: 1800  Loss: 0.0007747156778350472\n",
      "Epoch: 0  Batch: 2400  Loss: 0.014211039058864117\n",
      "Epoch: 0  Batch: 3000  Loss: 0.01345641165971756\n",
      "Epoch: 0  Batch: 3600  Loss: 0.009994076564908028\n",
      "Epoch: 0  Batch: 4200  Loss: 0.0039134849794209\n",
      "Epoch: 0  Batch: 4800  Loss: 0.003715724451467395\n",
      "Epoch: 0  Batch: 5400  Loss: 0.01206299476325512\n",
      "Epoch: 0  Batch: 6000  Loss: 0.17568042874336243\n",
      "Epoch: 1  Batch: 600  Loss: 0.0039933486841619015\n",
      "Epoch: 1  Batch: 1200  Loss: 0.13874538242816925\n",
      "Epoch: 1  Batch: 1800  Loss: 0.004636839032173157\n",
      "Epoch: 1  Batch: 2400  Loss: 0.001155938720330596\n",
      "Epoch: 1  Batch: 3000  Loss: 0.004312815144658089\n",
      "Epoch: 1  Batch: 3600  Loss: 0.011701542884111404\n",
      "Epoch: 1  Batch: 4200  Loss: 0.007058572024106979\n",
      "Epoch: 1  Batch: 4800  Loss: 0.00014502699195872992\n",
      "Epoch: 1  Batch: 5400  Loss: 0.4981679916381836\n",
      "Epoch: 1  Batch: 6000  Loss: 0.011390486732125282\n",
      "Epoch: 2  Batch: 600  Loss: 0.015416329726576805\n",
      "Epoch: 2  Batch: 1200  Loss: 0.028320426121354103\n",
      "Epoch: 2  Batch: 1800  Loss: 0.3720175623893738\n",
      "Epoch: 2  Batch: 2400  Loss: 0.0005203070468269289\n",
      "Epoch: 2  Batch: 3000  Loss: 0.000639689271338284\n",
      "Epoch: 2  Batch: 3600  Loss: 0.0338684543967247\n",
      "Epoch: 2  Batch: 4200  Loss: 0.0005654931301251054\n",
      "Epoch: 2  Batch: 4800  Loss: 0.01669226959347725\n",
      "Epoch: 2  Batch: 5400  Loss: 0.33262842893600464\n",
      "Epoch: 2  Batch: 6000  Loss: 0.00019900305778719485\n",
      "Epoch: 3  Batch: 600  Loss: 0.0014876394998282194\n",
      "Epoch: 3  Batch: 1200  Loss: 0.006084177643060684\n",
      "Epoch: 3  Batch: 1800  Loss: 0.0011756850872188807\n",
      "Epoch: 3  Batch: 2400  Loss: 0.011618422344326973\n",
      "Epoch: 3  Batch: 3000  Loss: 0.0007715602405369282\n",
      "Epoch: 3  Batch: 3600  Loss: 0.0001850977714639157\n",
      "Epoch: 3  Batch: 4200  Loss: 0.08808507025241852\n",
      "Epoch: 3  Batch: 4800  Loss: 7.754243415547535e-05\n",
      "Epoch: 3  Batch: 5400  Loss: 0.00021691419533453882\n",
      "Epoch: 3  Batch: 6000  Loss: 0.0004890369018539786\n",
      "Epoch: 4  Batch: 600  Loss: 8.129436173476279e-05\n",
      "Epoch: 4  Batch: 1200  Loss: 0.4094292223453522\n",
      "Epoch: 4  Batch: 1800  Loss: 3.133750578854233e-05\n",
      "Epoch: 4  Batch: 2400  Loss: 0.0001660606067162007\n",
      "Epoch: 4  Batch: 3000  Loss: 0.008535339497029781\n",
      "Epoch: 4  Batch: 3600  Loss: 0.0004267952754162252\n",
      "Epoch: 4  Batch: 4200  Loss: 0.0007839546306058764\n",
      "Epoch: 4  Batch: 4800  Loss: 0.00042277219472453\n",
      "Epoch: 4  Batch: 5400  Loss: 0.322590708732605\n",
      "Epoch: 4  Batch: 6000  Loss: 0.7896723747253418\n",
      "Training took: 4.7892672975858055 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_corr = 0\n",
    "    test_corr = 0\n",
    "    \n",
    "    #Training\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1  #starting the batches at 1\n",
    "        y_pred = cnn_model(X_train)  #getting the predicted values from the training set !matrix here is not flattened\n",
    "        loss = criterion(y_pred, y_train) #measuring the loss\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1] #finds the maximum value along dimension 1 and accesses the second element of the tuple \n",
    "                                                 #returned by torch.max(), which contains the indices of the maximum values.\n",
    "        batch_corrects = (predicted==y_train).sum()\n",
    "        train_corr += batch_corrects\n",
    "        \n",
    "        #update params\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b%600 == 0:\n",
    "            print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
    "            \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(train_corr)\n",
    "    \n",
    "    with torch.no_grad():  #weights are not updated\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            y_val = cnn_model(X_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            test_corr += (predicted==y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(test_corr)\n",
    "\n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f'Training took: {total/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165afa47",
   "metadata": {},
   "source": [
    "### Visualising the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "081d21e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f860e76bb80>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data=[td.item() for td in train_losses], label='Training losses')\n",
    "plt.plot(data=test_losses, label='Validation losses')\n",
    "plt.title('Loss at Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e890c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
